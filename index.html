<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Extreme (Elastic)Search</title>

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/night.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = 'css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
	<section>
	  <h2>Extreme (Elastic)Search</h2>
          <h4>everything is broken, complexity is born</h4>
          <p>
            &nbsp;
          </p>
	     <p>
	       <small>borislav.nikolov@booking.com</small>
	     </p>
	</section>

	<section>
	  <h2>What is ElasticSearch</h2>
	  <p>
            Java based distributed RESTful service on top of Lucene indexes.
	  </p>
	</section>

	<section>
	  <h2>What is Lucene</h2>
	  <p>
            information retrieval library based on inverted indexes and boolean model
	  </p>
	</section>


        <section>
	  <h2>What are Inverted Indexes</h2>
          <p>
            <em>few lines of code are worth a thausand words</em>
	    <code class='perl'>
              <pre>
my $book = [
        '... perl / ruby benchmark ...',      # 0
        '... perl / python benchmark ...',    # 1
        '... ruby / python benchmark ...',    # 2
        '... perl is awesome ...',            # 3
];

my $inverted = {
        'benchmark' => [ 0, 1, 2 ],
        'perl'      => [ 0, 1, 3 ],
        'ruby'      => [ 0, 2 ],
        'python'    => [ 1, 2 ],
};

# free stats:
my $n_documents      = scalar(@{ $book });
my $n_perl_documents = scalar(@{ $inverted->{perl} });
</pre>
</code>
documents in the inverted index are sorted by document id
</p>
	</section>

        <section>
	  <h2>perl AND ruby</h2>
          <p>
	    <code class='perl'>
              <pre>
   my @ids = search($inverted, "perl AND ruby");
   # matching: $book->[0]  "... perl / ruby benchmark ..."

   my @ids = search($inverted, "perl OR ruby");
   # matching: $book->[0], "... perl / ruby benchmark ..."
   #           $book->[2], "... ruby / python benchmark ..."
   #           $book->[1], "... perl / python benchmark ..."
   #           $book->[3], "... perl is awesome ..." // below ruby/python?
   #                                                 // "ruby" is less common than "perl"
</pre>
            </code>
            </ul>
          </p>
          <aside class="notes">
            boolean logic and set theory<br>
          </aside>

	</section>

	<section>
	  <h2>again: What is Lucene</h2>
	  <p>
            <ul>
              <li>actively developed</li>
              <li>open source</li>
              <li>fast</li>
              <li>extremely hackable</li>
            </ul>
            <aside class="notes">
              able to hack against its very core and design<br>
              blazingly fast<br>
              can losely estimate capacity if you want to change the query or explode the records<br>
              devs are not afraid of introducing non backward compatible features<br>
            </aside>
	  </p>
	</section>
        <section>
          <h2>again: What is ElasticSearch</h2>
          <p>
            <ul>
              <li>distributed</li>
              <li>takes care of things like
                <ul>
                    <li>replication</li>
                    <li>sharding</li>
                    <li>routing</li>
                </ul>
              </li>
              <li>awesome API</li>
              <li>cool plugins</li>
              <li>works out of the box</li>
            </ul>
          </p>
          <aside class="notes">
            has a bunch of lucene core developers<br>
            very friendly community<br>
            sharding:<br>
            just a part of the data<br>
            must merge results<br>
          </aside>
        </section>

        <section>
	  <h2>invent usecase</h2>
	  <p>
            <ul>
              <li><b>100_000_000</b> documents</li>
              <li><b>200</b> words per document</li>
              <li><b>1000</b> searches per second</li>
              <li><b>zero</b> tolerance for failure</li>
              <li><b>10ms</b> timeout</li>
              <li>usual query has to score <b>1_000_000</b> documents based on relevance</li>
            </ul>
	  </p>
          <aside class="notes">
            bing: 979 searches per second<br>
            incomparable of course<br>
          </aside>

	</section>
        <section>
          <h2>everything in one place</h2>
          count the <b>even</b> numbers from 0 up to 1_000_000
          <pre><code class="cpp">#include &lt;stdio.h&gt;
#include &lt;sys/time.h&gt;
int main(void) {
    int i,j;
    struct timeval t0,t1;
    gettimeofday(&amp;t0, 0);

    for (i = 0; i &lt; 1000000; i++)
        if (i % 2 == 0)
            j++;

    gettimeofday(&amp;t1, 0);
    printf("%ld\n", ((t1.tv_sec - t0.tv_sec) * 1000000 + t1.tv_usec - t0.tv_usec) / 1000);
}</code></pre>
          <p class="fragment">
            took: 5ms
          </p>
          <p class="fragment">
            split the work to 120 pieces, took: 47us
          </p>
        </section>
        <section>
	  <h2>estimate work per thread</h2>
	  <p>
            <ul>
              <li>split the 100m docs to <b>120</b> shards</li>
              <li>thread has to score on average 8333 (1/120th of 1_000_000)</li>
              <li><b>5 * 24 core boxes</b> can service a query within few ms</li>
              <li>24 boxes with 5 cpus will also do the job</li>
            </ul>
	  </p>
          <aside class="notes">
            sharding means we just split the data, thats it<br>
            one document score operation is constant time<br>
          </aside>
	</section>

        <section>
	  <h2>search </h2>
          <pre><code class='perl'>my @docs = ();
for (1.. (100_000_000 / 120)) { # 833333
    push @docs, { name => ($_ % 10 == 0 ? 'perl ruby' : 'perl') }
}
$engine->index(\@docs);
my $t0 = time();
my $results = search({
    bool => {
        must => [
            { term => { name => "perl"  } },
            { term => { name => "ruby" } }
        ]
    }
});
print "took: @{[ time() - $t0 ]}\n";</code></pre>
          <p class="fragment">
            5.8ms when every 10th document matches
          </p>
          <p class="fragment">
            0.7ms when all matching documents are in a block
          </p>
          <pre class="fragment"><code class='cpp'>//14 times slower than
for(i = 0; i < 9000; i++) { if (i % 2 == 0) j++; }</code></pre>
	</section>


        <section>
          <h2>perl AND ruby</h2>
          <p>
            <pre>
              <code>{
    'perl' => [ 1,   3,   277, 46000, 64973,   78688, ... ], # 876_962 documents
    'ruby' => [ 300, 456, 736, 837,   7278 ... 50000, ... ]  # 51_345 documents
}</code>
          </pre>
          <ol>
            <li class="fragment">pick a leading query</li>
            <li class="fragment">leading = 'ruby', at 300</li>
            <li class="fragment"><b>advance</b> 'perl' to 300 -> closest is 46000</li>
            <li class="fragment"><b>advance</b> 'ruby' to 46000 -> closest is 50000</li>
            <li class="fragment">goto 2. with target 50000</li>
          </ol>
          </p>
          <aside class="notes">
            worst case is that ALL documents from ruby match on perl<br>
          </aside>
        </section>
        <section>
          <h2>show me the code!</h2>
          "perl AND ruby"
          <p>
          <pre><code class='java'>int doNext(int target) throws Exception {
    for(;;) {
        try_again: for(;;) {
            for (int i = 1; i < queries.size(); i++) {
                Primitive q = queries.get(i);
                if (q.docID() < target) {
                    q.advance(target);
                    if (q.docID() > target) {
                        target = q.docID();
                        break try_again; // goto try_again # thank you java
                    }
                }
            }
            return target;
        }
        // try_again:
        target = lead.advance(target);
    }
}
</code></pre><pre><code class='java'>int next() throws Exception {
    return doNext(lead.nextDoc());
}
</code></pre><pre><code class='java'>while ((int doc = scorer.next()) != NO_MORE_DOCS) {
    collect(doc);
}</code></pre>
          </p>
          <aside class="notes">
            sorted doc ids<br>
            cheapest query is the lead query<br>
            advance() returns the closest document to the requested<br>
            leapfrog jumps<br>
            even the most complex query is aligning all subqueries to be on the same doc<br>
          </aside>
        </section>
        <section>
	  <h1>why does that matter?</h1>
          <ul>
            <li class="fragment">linear with number of <b>matching</b> documents</li>
            <li class="fragment">total number of documents is irrelevant</li>
            <li class="fragment">plan capacity</li>
            <li class="fragment">know your data, restrucutre if needed</li>
            <li class="fragment">plan for stress</li>
          </ul>
        </section>
        <section>
	  <h2>Wait, so what is really going on here?</h2>
	  <p>
            <ul>
              <li class="fragment">100_000_000 documents</li>
              <li class="fragment">sorting by relevance (using complex ranking functions)</li>
              <li class="fragment">on the fly</li>
              <li class="fragment">within milliseconds</li>
              <li class="fragment">using only 5 boxes</li>
              <li class="fragment">we dont need to worry about sharding/replication/distributed work, thanks to ElasticSearch</li>
            </ul>
	  </p>
	</section>

        <section>
	  <h2>120 shards, scatter/gather</h2>
	  <p>
            <ul>
              <li class="fragment">application asks random node<b>A</b></li>
              <li class="fragment">node<b>A</b> will ask one random node for each of the 120 shards</li>
              <li class="fragment">will merge the results</li>
            </ul>
	  </p>
	</section>

        <section>
	  <h1>we are good to go, except..</h1>
          <ul>
            <li class="fragment">everything that takes 100% resources is bound to thrash on itself</li>
            <li class="fragment">no downtime</li>
            <li class="fragment">maintenance</li>
            <li class="fragment">monitoring</li>
            <li class="fragment">GC</li>
          </ul>
            <aside class="notes">
              1 request 10ms<br>
              2 requests 25ms<br>
              3 requests 40ms<br>

              boxes will go down<br>
              you will have to move them around<br>
              groups of boxes are also likely to go down (switch issues, router issues, blade issues, rack issues)<br>
	      GC - it <b>will</b> stop randomly for at least a second<br>
              the dependencies a distributed system has are just <b>brutal</b>.
          </aside>
	</section>

        <section>
	  <h2>add more boxes</h2>
          <p>
            <ul>
              <li>+ replicas: throughput and resilience</li>
              <li>+ shards: decrease latency</li>
            </ul>
          </p>
	</section>
        <section>
          <h3>update/upgrade ElasticSearch/java/kernel</h3>
          <p>
            always stop shard reallocation first
          </p>
          <ul>

            <li class="fragment">rolling restart</li>
            <li class="fragment">cluster restart (<b>hope</b>, 99.9% uptime?)</li>
            <li class="fragment">cluster split (capacity?)</li>
            <li class="fragment">growing cluster (capacity?)</li>
          </ul>
          <aside class="notes">
            stop shard reallocataion<br>
            do you have enough capacity?<br>
            99.9% uptime?<br>
          </aside>
        </section>
        <section>
          <h2>master(s)</h2>
          <p>
            <ul>
              <li>create/delete/open/close of indexes</li>
              <li>shard (re)allocation</li>
              <li>index metadata</li>
            </ul>
          </p>
        </section>

        <section>
          <h2>split brain and data loss</h2>
          <p>
            <ul>
              <li>dedicated master nodes</li>
              <li>minimum master nodes - (N / 2) + 1</li>
              <li>zookeeper plugin</li>
            </ul>
            <img src="split.png" width=70%>
          </p>
        </section>
        <section>
          <h2>monitoring</h2>
          <p>
          <ul>
            <li>working indexing threads</li>
            <li>working search threads</li>
            <li>heap</li>
            <li>watching from outside is <b>not</b> enough</li>
            <li>each node should monitor the whole cluster's
              <ul>
                <li>latency</li>
                <li>loss</li>
              </ul>
            </li>
            <li>open file descriptors
              <ul>
                <li>segments</li>
              </ul>
            </li>
            <li>start with JMX so you can<br>profile/thread dump/heapdump with few mouse clicks</li>
          </ul>
          </p>
        </section>
        <section>
	  <h2>warstories</h2>
          <p>
            <ul>In my humble experience I have seen(unreproducable):
              <li>random stop/100% cpu</li>
              <li>reboot and never start again</li>
              <li>random crash (panics, jvm death etc)</li>
              <li>deadlock magic everywhere</li>
              <li>broken tcp state</li>
              <li>switch sending traffic only to ODD mac addresses</li>
              <li>NIC firmware messups</li>
              <li>everything started works, everything new hangs</li>
            </ul>
          </p>
          <p>
            mostly due to hardware issues, triggering weird behavior in unpredictable ways
          </p>
        </section>

        <section>
          <h3>how did we get here?</h3>
          <p>
            we just want to <b>store</b> and <b>search</b>
          </p>
        </section>

        <section>
          <h4>how to store JSON in Lucene</h4>
          <p>
            <pre><code class='java'>// read [ { "field": "value" }, .. ] from STDIN and store each hash as a Lucene document
// thank you stackoverflow
IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_48,whitespace);
config.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
IndexWriter writer = new IndexWriter(new NIOFSDirectory(ROOT),config);
JsonReader json = new JsonReader(new InputStreamReader(System.in, "UTF-8"));
Gson gson = new Gson();
Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;();

json.beginArray();
while (json.hasNext()) {
    map = (Map&lt;String,String&gt;) gson.fromJson(json, map.getClass());
    Document doc = new Document();
    for (Map.Entry&lt;String,String&gt; entry : map.entrySet())
        doc.add(new Field(entry.getKey(), entry.getValue(),
                Field.Store.YES,
                Field.Index.ANALYZED));
    writer.addDocument(doc);
}
json.endArray();
json.close();</code></pre></p>
        </section>
        <section>
          <h4>how to search in Lucene</h4><p>
          <pre><code class='java'>// return top documents matching 'perl AND ruby' as [ { "key":"value" }.. ]
IndexReader reader = DirectoryReader.open(writer,false);
IndexSearcher searcher = new IndexSearcher(reader);
Query q = new BooleanQuery();
q.add(new TermQuery(new Term("name","perl")),BooleanClause.Occur.MUST);
q.add(new TermQuery(new Term("name","ruby")),BooleanClause.Occur.MUST);
TopDocs results = searcher.search(q, null,100);
ScoreDoc[] hits = results.scoreDocs;
List&lt;Map&lt;String,String&gt;&gt; output = new ArrayList&lt;Map&lt;String,String&gt;&gt;();
for(int i = 0; i &lt; hits.length; i++) {
    Document doc = searcher.doc(hits[i].doc);
    Map&lt;String,String&gt; item = new Map&lt;String,String&gt;();
    item.put("_score",hits[i].score);
    for (IndexableField field : doc.getFields())
        item.put(field.name(),field.stringValue());
    output.put(item);
}
reader.close();
return output;</code></pre></p>
        </section>
        <section>
          <h2>hack your own search</h2>
          <p>using sun.http or netty or jetty or whatever tty you like, you can easilly hack your own search service</p>
          <p>&nbsp;</p>
          <p>simple topN recepie</p>
          <ul>
            <li>build 5 "shards" each containing 24 Lucene indexes</li>
            <li>copy "shard" per box</li>
            <li>get topN from 5 boxes</li>
            <li><code>sort { $b->{_score} <=> $a->{_score} } @r</code></li>
            <li>profit</li>
          </ul>
          <hr>
          <small>and have your very own unexpected problems :)</small>
        </section>
        <section>
          <h2>summary</h2>
          <ul>
            <li>nothing is as easy as it seems</li>
            <li>everything can and <b>will break</b></li>
            <li>just assume it is <b>broken</b> already</li>
            <li>dont be afraid to <b>hack</b> your way through the forest</li>
            <li>when it rains, it pours</li>
        </section>
        <section>
            <ul>
              <li>Lucene 4.9<br>http://lucene.apache.org/core/4_9_0/core/index.html</li>
              <li>Lucene in Action<br>http://amzn.com/1933988177</li>
              <li>examples about Lucene's hackability<br>https://github.com/jackdoe/drunken-octo-batman/</li>
              <li>ElasticSearch<br>https://github.com/elasticsearch/elasticsearch</li>
            </ul>
        </section>
	<section>
	  <h1>thank you</h1>
	</section>
      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>

    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,

      theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
      transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

      // Parallax scrolling
      // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
      // parallaxBackgroundSize: '2100px 900px',

      // Optional libraries used to extend on reveal.js
      dependencies: [
      { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
      ]
      });

    </script>

  </body>
</html>
