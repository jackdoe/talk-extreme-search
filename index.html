<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Extreme (Elastic)Search</title>

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/night.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = 'css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
	<section>
	  <h2>Extreme (Elastic)Search</h2>
          <h4>everything is broken, complexity is born</h4>
          <p>
            &nbsp;
          </p>
	     <p>
	       <small>borislav.nikolov@booking.com</small>
	     </p>
	</section>

	<section>
	  <h2>What is ElasticSearch</h2>
	  <p>
            Java based distributed RESTful service on top of Lucene indexes.
	  </p>
	</section>

	<section>
	  <h2>What is Lucene</h2>
	  <p>
            information retrieval library based on inverted indexes and boolean model
	  </p>
          <aside class="notes">
            what is information retrieval<br>
            the activity of getting relevant information<br>
            precision - what part of the retrieved documents are relevant to the user<br>
            recall - the probability that a relevant document is retrieved by the query<br>
            fall-out - the probability that a non-relevant document is retrieved by the query
          </aside>
	</section>


        <section>
	  <h2>What are Inverted Indexes</h2>
          <p>
            <em>few lines of code are worth a thausand words</em>
	    <code class='perl'>
              <pre>
my $forward = [
        'new york',        # 0
        'paris',           # 1
        'new york state',  # 2
        'new hotel'        # 3
];

my $inverted = {
        'new'   => [ 0, 2, 3 ],
        'york'  => [ 0, 2 ],
        'paris' => [ 1 ],
        'state' => [ 2 ],
        'hotel' => [ 3 ]
};
</pre>
</code>
documents in the inverted index are sorted by document id
</p>
	</section>

        <section>
	  <h2>What is the boolean model</h2>
          <p>
	    <code class='perl'>
              <pre>
   my @ids = search("new AND york");
   # 0, 2
   # fetch from the forward index: $forward->[0], $forward->[2]

   my @ids = search("new OR york");
   # 0, 2, 3
   # fetch from the forward index: $forward->[0],
   #                               $forward->[2],
   #                               $forward->[3]
</pre>
            </code>
            <ul>
              <li>AND: 2 comparisons</li>
              <li>OR: 3 comparisons</li>
            </ul>
          </p>
          <aside class="notes">
            boolean logic and set theory<br>
          </aside>

	</section>

	<section>
	  <h2>again: What is Lucene</h2>
	  <p>
            <ul>
              <li>amazing</li>
              <li>actively developed</li>
              <li>open source</li>
              <li>fast</li>
              <li>extremely hackable</li>
            </ul>
            <aside class="notes">
              amazing<br>
              able to hack against its very core and design<br>
              blazingly fast<br>
              can losely estimate capacity if you want to change the query or explode the records<br>
              devs are not afraid of introducing non backward compatible features<br>
            </aside>
	  </p>
	</section>
        <section>
          <h2>again: What is ElasticSearch</h2>
          <p>
            <ul>
              <li>distributed</li>
              <li>takes care of things like
                <ul>
                    <li>replication</li>
                    <li>sharding</li>
                    <li>routing</li>
                </ul>
              </li>
              <li>awesome API</li>
              <li>cool plugins</li>
              <li>works out of the box</li>
            </ul>
          </p>
          <aside class="notes">
            has a bunch of lucene core developers<br>
            very friendly community<br>
            sharding:<br>
            just a part of the data<br>
            must merge results<br>
          </aside>
        </section>

        <section>
	  <h2>invent usecase</h2>
	  <p>
            <ul>
              <li><b>100_000_000</b> documents</li>
              <li><b>1000</b> searches per second</li>
              <li><b>zero</b> tolerance for failure</li>
              <li><b>10ms</b> timeout</li>
              <li>usual query has to score <b>1_000_000</b> documents based on relevance</li>
            </ul>
	  </p>
          <aside class="notes">
            bing: 979 searches per second<br>
            incomparable of course<br>
          </aside>

	</section>
        <section>
          <h2>everything in one place</h2>
          <pre><code class="cpp">#include &lt;stdio.h&gt;
#include &lt;sys/time.h&gt;
int main(void) {
    int i,j;
    struct timeval t0,t1;    

    gettimeofday(&amp;t0, 0);    
    for (i = 0; i &lt; 1000000; i++)
        if (i % 2 == 0)
            j++;
    gettimeofday(&amp;t1, 0);
    printf("%ld\n", ((t1.tv_sec - t0.tv_sec) * 1000000 + t1.tv_usec - t0.tv_usec) / 1000);
}</code></pre>
          <p class="fragment">
            5ms
          </p>
          <p class="fragment">
            47us with 9000
          </p>
        </section>
        <section>
	  <h2>estimate work per thread</h2>
	  <p>
            <ul>
              <li>split the 100m docs to <b>120</b> shards</li>
              <li>thread has to score on average 8333 (1/120th of 1_000_000)</li>
              <li><b>5 * 24 core boxes</b> can service a query within few ms</li>
              <li>24 boxes with 5 cpus will also do the job</li>
            </ul>
	  </p>
          <aside class="notes">
            sharding means we just split the data, thats it<br>
            one document score operation is constant time<br>
          </aside>
	</section>

        <section>
	  <h2>on my laptop</h2>
          <pre><code class='perl'>my @docs = ();
for (1.. (100_000_000 / 120)) {
    push @docs, { name => ($_ % 10 == 0 ? 'new york' : 'new') }
}
$engine->index(\@docs);
my $t0 = time();
my $results = search({
    bool => {
        must => [
            { term => { name => "new"  } },
            { term => { name => "york" } }
        ]
    }
                    });
print "took: @{[ time() - $t0 ]}\n";</code></pre>
          <p class="fragment">
            5.8ms when every 10th document matches
          </p>
          <p class="fragment">
            0.7ms when all matching documents are in a block
          </p>
          <pre class="fragment"><code class='cpp'>//14 times slower than
for(i = 0; i < 9000; i++) { if (i % 2 == 0) j++; }</code></pre>
	</section>

        <section>
	  <h2>Wait, so what is really going on here?</h2>
	  <p>
            <ul>
              <li>100_000_000 documents</li>
              <li>finding</li>
              <li>sorting</li>
              <li>by relevance</li>
              <li>on the fly</li>
              <li>within milliseconds</li>
              <li>using only 5 boxes</li>
            </ul>
	  </p>
          <aside class="notes">
          </aside>
	</section>

        <section>
	  <h1>how cool is that?</h1>
	</section>
        <section>
          <h2>new AND york</h2>
          <p>
            <pre>
              <code>{
    'new'  => [ 1,   3,   277, 46839, 64973,   78688, ... ], # 876_962 documents
    'york' => [ 300, 456, 736, 837,   7278 ... 50000, ... ]  # 51_345 documents
}</code>
          </pre>
          <ol>
            <li class="fragment">pick a leading query</li>
            <li class="fragment">leading = 'york', at 300</li>
            <li class="fragment"><b>advance</b> 'new' to 300 -> closest is 46839</li>
            <li class="fragment"><b>advance</b> leading(york) to 46839 -> closest is 50000</li>
            <li class="fragment">goto 2. with target 50000</li>
          </ol>
          </p>
          <aside class="notes">
            worst case is that ALL documents from york match on new<br>
          </aside>
        </section>        
        <section>
          <h2>show me the code!</h2>
          "new AND york"
          <p>
          <pre><code class='java'>int doNext(int target) throws Exception {
    for(;;) {
        try_again: for(;;) {
            for (int i = 1; i < queries.size(); i++) {
                Primitive q = queries.get(i);
                if (q.docID() < target) {
                    q.advance(target);
                    if (q.docID() > target) {
                        target = q.docID();
                        break try_again; // goto try_again # thank you java
                    }
                }
            }
            return target;
        }
        // try_again:                        
        target = lead.advance(target);
    }
}
</code></pre><pre><code class='java'>int next() throws Exception {
    return doNext(lead.nextDoc());
}
</code></pre><pre><code class='java'>while ((int doc = scorer.next()) != NO_MORE_DOCS) {
    collect(doc);
}</code></pre>
          </p>
          <aside class="notes">
            sorted doc ids<br>
            cheapest query is the lead query<br>
            advance() returns the closest document to the requested<br>
            leapfrog jumps<br>
            even the most complex query is aligning all subqueries to be on the same doc<br>
          </aside>

        </section>
        <section>
	  <h1>few issues to fix, then we're good to go</h1>
	</section>

        <section>
	  <h2>everything that takes 100% resources is bound to thrash on itself</h2>
          <p>
            <center>
            <table>
              <tr><td>1</td><td>request</td><td>10ms</td></tr>
              <tr><td>2</td><td>sequential</td><td>20ms</td></tr>
              <tr><td>2</td><td>simultaneous</td><td>25ms</td></tr>
              <tr><td>3</td><td>simultaneous</td><td>40ms</td></tr>
            </table>
            </center>
            <hr>
          <b>add more boxes</b>
          <ul>
            <li>reduces number of requests per box</li>
            <li>increase the number of shards, reduce time spend per request</li>
          </ul>
          </p>
	</section>

        <section>
	  <h2>no box can be down</h2>
          <p>
            <b>add more boxes, increase number of index replicas</b>
          </p>
          <aside class="notes">
            boxes will go down<br>
            you will have to move them around<br>
            groups of boxes are also likely to go down (switch issues, router issues, blade issues, rack issues)<br>
          </aside>
	</section>

        <section>
	  <h2>rince and repeat</h2>
          <p>
            <b>add more boxes</b>
            <ul>
              <li>increase throughput and resiliende by adding replicas</li>
              <li>decrease latency by increaseing the number of shards</li>
            </ul>
          </p>
	</section>


        <section>
	  <h2>GC - it <b>will</b> stop randomly for at least a second</h2>
          <p>
            <ul>
              <li>what if it stops for 10 seconds?</li>
              <li>be carefull with your heap size</li>
              <li>force GC from outside using JMX</li>
              <li>write Elaticsearch extension to create GC API endpoint</li>
              <li>have 2 clusters, one doing GC and one serving traffic</li>
              <li>have N identical indexes, using custom shard allocation</li>
              <li>?_preference=_only_node:node_id</li>
            </ul>
          </p>
	</section>
        <section>
          <h2>quickly recovering from a disaster</h2>
          <p>
          <ul>
            <li>node is dead</li>
            <li>cluster is red</li>
            <li>starts moving things around</li>
            <li>node comes back</li>
            <li>while building indexes and serving queries</li>
          </ul>
          </p>
        </section>
        <section>
	  <h2>dependencies</h2>
          <p>
            the dependencies a distributed system has are just <b>brutal</b>.
          </p>
        </section>

        <section>
	  <h2>single box</h2>
          lets assume that there are <b>0 bugs per line</b>
          <hr>
          <center>
            <table>
              <tr><td>ElasticSearch</td><td>400k</td></tr>
              <tr><td>libraries used by ElasticSearch</td><td>100k</td></tr>
              <tr><td>JVM</td><td>3.5m</td></tr>
              <tr><td>linux</td><td>16m</td></tr>
              <tr><td>flawless tcp stack</td><td>since 1981</td></tr>
              <tr><td>hardware is just brilliant</td><td>-</td></tr>
              <tr><td>network cables are awesome</td><td>-</td></tr>
              <tr><td>switches (juniper)</td><td>5m management</td></tr>
              <tr><td>temperature 15C</td><td>-</td></tr>
              <tr><td>humidity 40%</td><td>-</td></tr>
            </table>
            total lines of code: <b>25_000_000</b>, humans: <b>?</b>
          </center>
          <aside class="notes">
            picture that<br>
            from the jvm<br>
            thru the kernel<br>
            thru the tcp stack<br>
            into the ip stack<br>
            into one of network card's queues<br>
            thru the cables<br>
            into the switch<br>
            the destination mac lookup<br>
            the router's interface
            and the other way around up to
            client.read()
          </aside>
        </section>

        <section>
	  <h2>so how many truly <b>untested|undefined</b> codepaths are there?</h2>
          <p>
            <ul>in my humble experience i have seen(unreproducable):
              <li>random stop</li>
              <li>random 100% cpu</li>
              <li>reboot and never start again</li>
              <li>random crash (panics, jvm death etc)</li>
              <li>deadlock magic everywhere</li>
              <li>broken tcp state</li>
              <li>switch sending traffic only to ODD mac addresses</li>
              <li>NIC firmware messups</li>
              <li>everything started works, everything new hangs</li>
            </ul>
          </p>
          most of those are due to hardware issues, triggering weird behavior that bubbles up in unpredictable ways
        </section>

        <section>
          <h2>so lets couple 5 of those monsters to have hard dependency on each other</h2>
          <p>
            <ul>
              <li>agree on state</li>
              <li>trust</li>
            </ul>
          <hr>
          now tell me again, how easy it is to make that work
          </p>
        </section>
        <section>
          <h2>game</h2>
          <pre><code class='cpp'>#define XY(x,y)     ((x) &lt;&lt; 32 | (y))
#define GET_X(pos)  ((pos) &gt;&gt; 32)
#define GET_Y(pos)  ((pos) & 0xFFFFFFFF)
#define STEP_X(pos) XY(GET_X(pos) + 1,GET_Y(pos))
#define STEP_Y(pos) XY(GET_X(pos),GET_Y(pos) + 1)
uint64_t position = 0;</code></pre>
                        <p>
                          <ul>
                            <li>position encoded as <b>one</b> 64 bit integer</li>
                            <li>5 <b>online</b> players</li>
                            <li>mine for gold</li>
                            <li><b>no</b> collisions</li>
                        </ul>
                        </p>
                        <img src="game.png" width=50%>
                        <aside class="notes">
                          centralized<br><br>
                          distributed<br><br>
                          what is distributed<br>
                          means that things communicate and interact with each other by passing messages to reach a common goal<br>
                          2 phase commit:<br>
                          prepare phase<br>
                          commit phase<br>
                          raft:<br>
                          leader election<br>
                          replication log<br>
                          get Paxos/Raft implementation
                          just use ZooKeeper (proto is inspired by Paxos)
                        </aside>
        </section>
        <section>
          <h2>ElasticSearch - how do you update stuff</h2>
          <p>
          <ul>
            <li>Java minor version bump</li>
            <li>ElasticSearch</li>
            <li>kernel</li>
          </ul>
          </p>
        </section>
        <section>
          <h2>rolling</h2>
          <p>
          <ul>
            <li>stop shard reallocation</li>
            <li>shut down the node</li>
            <li>update</li>
            <li>start</li>
            <li>wait to join</li>
            <li>repeat</li>
          </ul>
          </p>
        </section>

        <section>
          <h2>cluster restart</h2>
          <p>
          <ul>
            <li>disable reallocation</li>
            <li>shut down everything</li>
            <li>update</li>
            <li>start</li>
            <li>hope</li>
          </ul>
          <hr>
          huh? what about 99.9% uptime?
          </p>
        </section>
        <section>
          <h2>cluster split</h2>
          <p>
          <ul>
            <li>split the cluster in 2</li>
            <li>move all traffic to 1/2 of it</li>
            <li>update the other 1/2</li>
            <li>move the traffic back</li>
            <li>update first 1/2</li>
            <li>join them</li>
          </ul>
          <hr>
          wait, that requires 100% over-capacity
          </p>
        </section>

        <section>
          <h2>growing cluster</h2>
          <p>
          <ul>
            <li>take one node out to new cluster</li>
            <li>update it</li>
            <li>move all the traffic to this cluster</li>
            <li>repeat: take one more box out of the old cluster</li>
            <li>update it</li>
            <li>move it to the new cluster</li>
            <li>goto repeat</li>
          </ul>
          <hr>
          wait, can one node service 100% of the requests?
          <hr>
          <small>maybe we will just stop for 20 minutes in the middle of the night, nobody will notice..</small>
          </p>
        </section>
        <section>
          <h2>who is in charge?</h2>
          <p>
          <ul>
            <li>create/delete/open/close of indexes</li>
            <li>shard allocation</li>
            <li>index metadata</li>
          </ul>
          <hr>
          <b>master</b>
          </p>
        </section>

        <section>
          <h2>split brain and point of view</h2>
          <p>
            <ul>
              <li>master election</li>
              <li>pressure</li>
              <li>master only nodes</li>
              <li>minimum master nodes</li>
            </ul>
            <img src="split.png" width=70%>
          </p>
        </section>
        <section>
          <h2>monitoring</h2>
          <p>
          <ul>
            <li>working indexing threads</li>
            <li>working search threads</li>
            <li>heap</li>
            <li>watching from outside is <b>not</b> enough</li>
            <li>each node should monitor the whole cluster's
              <ul>
                <li>latency</li>
                <li>loss</li>
              </ul>
            </li>
            <li>openfds
              <ul>
                <li>segments</li>
              </ul>
            </li>
          </ul>
          </p>
        </section>
        <section>
          <h2>wait, what were Inverted Indexes again?</h2>
          <p>
          <ul>do you really need?
            <li>distributed system</li>
            <li>updateable indexes</li>
            <li>nice REST API</li>
          </ul>
          <hr>
          we just want to <b>store</b> and <b>search</b>
          </p>
        </section>

        <section>
          <h2>game - partial world</h2>
          <p>
            <pre><code class='c'>uint64_t partial[] = { XY(0,0) };                   // player 0
uint64_t partial[] = { XY(1,0) };                   // player 1
uint64_t partial[] = { XY(2,0) };                   // player 2
uint64_t partial[] = { XY(0,1) XY(1,1), XY(2,1) };  // player 3
uint64_t partial[] = { XY(0,2) XY(1,2), XY(2,2) };  // player 4</code></pre>
          <ul>
            <li>+simple</li>
            <li>+players do not need to be aware of each other</li>
            <li>-someone else must do the gold merge</li>
          </ul>
          </p>
        </section>

        <section>
          <h4>store</h4>
          <p>
            <pre><code class='java'>// read [ { "field": "value" }, .. ] from STDIN and store each hash as a Lucene document
// thank you stackoverflow
IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_48,whitespace);
config.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
IndexWriter writer = new IndexWriter(new NIOFSDirectory(ROOT),config);
JsonReader json = new JsonReader(new InputStreamReader(System.in, "UTF-8"));
Gson gson = new Gson();
Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;();

json.beginArray();
while (json.hasNext()) {
    map = (Map&lt;String,String&gt;) gson.fromJson(json, map.getClass());
    Document doc = new Document();
    for (Map.Entry&lt;String,String&gt; entry : map.entrySet())
        doc.add(new Field(entry.getKey(), entry.getValue(),
                Field.Store.YES,
                Field.Index.ANALYZED));
    writer.addDocument(doc);
}
json.endArray();
json.close();</code></pre></p>
        </section>
        <section>
          <h4>search</h4><p>
          <pre><code class='java'>// return top documents matching 'new AND york' as [ { "key":"value" }.. ]
IndexReader reader = DirectoryReader.open(writer,false);
IndexSearcher searcher = new IndexSearcher(reader);
Query q = new BooleanQuery();
q.add(new TermQuery(new Term("name","new")),BooleanClause.Occur.MUST);
q.add(new TermQuery(new Term("name","york")),BooleanClause.Occur.MUST);
TopDocs results = searcher.search(q, null,100);
ScoreDoc[] hits = results.scoreDocs;
List&lt;Map&lt;String,String&gt;&gt; output = new ArrayList&lt;Map&lt;String,String&gt;&gt;();
for(int i = 0; i &lt; hits.length; i++) {
    Document doc = searcher.doc(hits[i].doc);
    Map&lt;String,String&gt; item = new Map&lt;String,String&gt;();
    item.put("_score",hits[i].score);
    for (IndexableField field : doc.getFields())
        item.put(field.name(),field.stringValue());
    output.put(item);
}
reader.close();
return output;</code></pre></p>
        </section>
        <section>
          <p>using sun.http or netty or jetty or whatever tty you like, you can easilly hack your own search service</p>
          <p>&nbsp;</p>
          <p>simple topN recepie</p>
          <ul>
            <li>build 5 "shards" each containing 24 Lucene indexes</li>
            <li>copy "shard" per box</li>
            <li>get topN from 5 boxes</li>
            <li><code>sort { $b->{_score} <=> $a->{_score} } @r</code></li>
            <li>profit</li>
          </ul>
          <hr>
          <small>and have your very own unexpected problems :)</small>
        </section>
        <section>
          <h2>summary</h2>
          <ul>
            <li>nothing is as easy as it seems</li>
            <li>everything can and <b>will break</b></li>
            <li>just assume it is <b>broken</b> already</li>
            <li>dont be afraid to <b>hack</b> your way through the forest</li>
            <li>when it rains, it pours</li>
        </section>
        <section>
            <ul>
              <li>Lucene 4.9<br>http://lucene.apache.org/core/4_9_0/core/index.html</li>
              <li>Lucene in Action<br>http://amzn.com/1933988177</li>
              <li>examples about Lucene's hackability<br>https://github.com/jackdoe/drunken-octo-batman/</li>
              <li>ElasticSearch<br>https://github.com/elasticsearch/elasticsearch</li>
            </ul>
        </section>
	<section>
	  <h1>thank you</h1>
	</section>

      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>

    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      center: true,

      theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
      transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

      // Parallax scrolling
      // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
      // parallaxBackgroundSize: '2100px 900px',

      // Optional libraries used to extend on reveal.js
      dependencies: [
      { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
      { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
      ]
      });

    </script>

  </body>
</html>
